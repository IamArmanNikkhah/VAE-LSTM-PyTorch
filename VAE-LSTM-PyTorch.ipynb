{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOM4B061vXAhMTwNGleG4wn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.pyplot import figure, plot, savefig\n","import time"],"metadata":{"id":"mh0NIGW310zl","executionInfo":{"status":"ok","timestamp":1712779923141,"user_tz":300,"elapsed":9932,"user":{"displayName":"Arman Nikkhah","userId":"16750917565129391933"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["class Encoder(nn.Module):\n","    def __init__(self, config):\n","        super(Encoder, self).__init__()\n","\n","        self.config = config\n","        num_hidden_units = self.config['num_hidden_units']\n","        n_channel = self.config['n_channel']\n","        code_size = self.config['code_size']\n","        self.l_win = config['l_win']\n","\n","        self.conv1 = nn.Conv2d(in_channels=n_channel, out_channels=num_hidden_units // 16, kernel_size=(3, n_channel), stride=(2, 1), padding='same')\n","        self.conv2 = nn.Conv2d(num_hidden_units // 16, out_channels=num_hidden_units // 8, kernel_size=(3, n_channel), stride=(2, 1), padding='same')\n","        self.conv3 = nn.Conv2d(num_hidden_units // 8, out_channels=num_hidden_units // 4, kernel_size=(3, n_channel), stride=(2, 1), padding='same')\n","        self.conv4 = nn.Conv2d(num_hidden_units // 4, out_channels=num_hidden_units, kernel_size=(4, n_channel), stride=1, padding='valid')\n","        self.conv5 = nn.Conv2d(in_channels=num_hidden_units // 4, out_channels=num_hidden_units, kernel_size=(6, n_channel), stride=1, padding='valid')\n","\n","        self.flatten = nn.Flatten()\n","        self.fc1 = nn.Linear(self._get_conv_output_shape(), code_size * 4)\n","        self.code_mean = nn.Linear(code_size * 4, code_size)\n","        self.code_std_dev = nn.Linear(code_size * 4, code_size)\n","\n","    def forward(self, x):\n","        x = x.unsqueeze(1)  # Add channel dimension\n","\n","        if self.l_win == 24:\n","            x = F.pad(x, (0, 0, 4, 4), mode='reflect')\n","            x = F.leaky_relu(self.conv1(x))\n","            print(\"conv_1:\", x.size())\n","            x = F.leaky_relu(self.conv2(x))\n","            print(\"conv_2:\", x.size())\n","            x = F.leaky_relu(self.conv3(x))\n","            print(\"conv_3:\", x.size())\n","            x = F.leaky_relu(self.conv4(x))\n","            print(\"conv_4:\", x.size())\n","\n","        if self.l_win == 48:\n","            x = F.leaky_relu(self.conv)\n","            print(\"conv_1:\", x.size())\n","            x = F.leaky_relu(self.conv2(x))\n","            print(\"conv_2:\", x.size())\n","            x = F.leaky_relu(self.conv3(x))\n","            print(\"conv_3:\", x.size())\n","            x = F.leaky_relu(self.conv5(x))\n","            print(\"conv_5:\", x.size())\n","\n","        x = self.flatten(x)\n","        x = F.leaky_relu(self.fc1(x))\n","\n","        code_mean = self.code_mean(x)\n","        code_std_dev = F.relu(self.code_std_dev(x)) + 1e-2  # Ensure std_dev is positive\n","\n","        # Sampling from the distribution\n","        normal_dist = dist.Normal(loc=code_mean, scale=code_std_dev)\n","        code_sample = normal_dist.rsample()  # Reparameterization trick for backpropagation\n","\n","        print(\"finish encoder: \\n{}\".format(self.code_sample))\n","        print(\"\\n\")\n","\n","        return code_sample, code_mean, code_std_dev\n"],"metadata":{"id":"mNAXtCmbwD7E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import math\n","\n","class Encoder(nn.Module):\n","    def __init__(self, config):\n","        super(Encoder, self).__init__()\n","\n","        self.config = config\n","        num_hidden_units = self.config['num_hidden_units']\n","        n_channel = self.config['n_channel']\n","        code_size = self.config['code_size']\n","        self.l_win = config['l_win']\n","\n","        self.conv1 = nn.Conv2d(in_channels=1, out_channels=num_hidden_units // 16, kernel_size=(3, n_channel), stride=(2, 1))\n","        self.conv2 = nn.Conv2d(num_hidden_units // 16, out_channels=num_hidden_units // 8, kernel_size=(3, n_channel), stride=(2, 1))\n","        self.conv3 = nn.Conv2d(num_hidden_units // 8, out_channels=num_hidden_units // 4, kernel_size=(3, n_channel), stride=(2, 1))\n","        self.conv4 = nn.Conv2d(num_hidden_units // 4, out_channels=num_hidden_units, kernel_size=(4, n_channel), stride=1, padding='valid')\n","        self.conv5 = nn.Conv2d(num_hidden_units // 4, out_channels=num_hidden_units, kernel_size=(6, n_channel), stride=1, padding='valid')\n","\n","        self.flatten = nn.Flatten()\n","        self.fc1 = nn.Linear(num_hidden_units, code_size * 4)\n","        self.code_mean = nn.Linear(code_size * 4, code_size)\n","        self.code_std_dev = nn.Linear(code_size * 4, code_size)\n","\n","\n","    def same_padding(self,x, kernel_size, stride):\n","        if isinstance(kernel_size, tuple):\n","            kernel_height, kernel_width = kernel_size\n","        else:\n","            kernel_height = kernel_width = kernel_size\n","\n","        if isinstance(stride, tuple):\n","            stride_height, stride_width = stride\n","        else:\n","            stride_height = stride_width = stride\n","\n","        input_size = x.size()\n","\n","        out_height = math.ceil(float(input_size[0]) / float(stride_height))\n","        out_width  = math.ceil(float(input_size[1]) / float(stride_width))\n","\n","        pad_along_height = max((out_height - 1) * stride_height + kernel_height - input_size[0], 0)\n","        pad_along_width = max((out_width - 1) * stride_width + kernel_width - input_size[1], 0)\n","\n","        pad_top = pad_along_height // 2\n","        pad_bottom = pad_along_height - pad_top\n","        pad_left = pad_along_width // 2\n","        pad_right = pad_along_width - pad_left\n","\n","        pad = (pad_left, pad_right, pad_top, pad_bottom)\n","\n","        return F.pad(x, pad, mode='replicate')\n","\n","\n","\n","\n","    def forward(self, x):\n","        x = x.unsqueeze(1)  # Add channel dimension\n","        print(\"unsqueeze:\", x.size())\n","\n","        if self.l_win == 24:\n","\n","            x = F.pad(x, (0, 0, 4, 4), mode='replicate')\n","            x = self.same_padding(x, (3, self.config['n_channel']), (2, 1))\n","            x = F.leaky_relu(self.conv1(x))\n","            print(\"conv_1:\", x.size())\n","\n","            x = self.same_padding(x, (3, self.config['n_channel']), (2, 1))\n","            x = F.leaky_relu(self.conv2(x))\n","            print(\"conv_2:\", x.size())\n","\n","            x = self.same_padding(x, (3, self.config['n_channel']), (2, 1))\n","            x = F.leaky_relu(self.conv3(x))\n","            print(\"conv_3:\", x.size())\n","\n","            x = F.leaky_relu(self.conv4(x))\n","            print(\"conv_4:\", x.size())\n","\n","        elif self.l_win == 48:\n","\n","            x = self.same_padding(x, (3, self.config['n_channel']), (2, 1))\n","            x = F.leaky_relu(self.conv1(x))\n","            print(\"conv_1:\", x.size())\n","\n","            x = self.same_padding(x, (3, self.config['n_channel']), (2, 1))\n","            x = F.leaky_relu(self.conv2(x))\n","            print(\"conv_2:\", x.size())\n","\n","            x = self.same_padding(x, (3, self.config['n_channel']), (2, 1))\n","            x = F.leaky_relu(self.conv3(x))\n","            print(\"conv_3:\", x.size())\n","\n","            x = F.leaky_relu(self.conv5(x))\n","            print(\"conv_5:\", x.size())\n","\n","        x = self.flatten(x)\n","        print(\"flatten:\", x.size())\n","        x = F.leaky_relu(self.fc1(x))\n","\n","        code_mean = self.code_mean(x)\n","        code_std_dev = F.relu(self.code_std_dev(x)) + 1e-2  # Ensure std_dev is positive\n","\n","        # Sampling from the distribution\n","        normal_dist = dist.Normal(loc=code_mean, scale=code_std_dev)\n","        code_sample = normal_dist.rsample()  # Reparameterization trick for backpropagation\n","\n","        print(\"finish encoder: \\n{}\".format(code_sample))\n","        print(\"\\n\")\n","\n","        return code_sample, code_mean, code_std_dev"],"metadata":{"id":"hdGedgkOtOK9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.distributions as dist\n","import torch.nn.functional as F\n","\n","# Paste the provided Encoder class code here\n","\n","def test_encoder(config):\n","    \"\"\"\n","    Test the correctness of the Encoder model.\n","\n","    Args:\n","        config (dict): Configuration dictionary containing model hyperparameters.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    # 1. Summarize the provided code\n","    print(\"Encoder Model Summary:\")\n","    print(\"- The Encoder model takes an input tensor and encodes it into a latent code representation.\")\n","    print(\"- It consists of convolutional layers followed by fully connected layers.\")\n","    print(\"- The model outputs the latent code sample, mean, and standard deviation.\")\n","\n","    # 2. Load the provided model and prepare the testing dataset\n","    encoder = Encoder(config)\n","    print(\"\\nEncoder Model Architecture:\")\n","    print(encoder)\n","\n","    # Prepare sample input data with different shapes\n","    input_shapes = [(48, 10)]\n","\n","    # 3. Implement a testing procedure to evaluate the model's calculation on input matrices with different shapes\n","    print(\"\\nTesting Encoder Model:\")\n","    for shape in input_shapes:\n","        print(f\"\\nTesting with input shape: {shape}\")\n","        input_data = torch.randn(1, *shape)  # Create random input data with the specified shape\n","\n","        # Forward pass through the encoder\n","        code_sample, code_mean, code_std_dev = encoder(input_data)\n","\n","        # 4. Display or print the results of the model evaluation\n","        print(\"Encoder Output:\")\n","        print(\"- Code Sample Shape:\", code_sample.shape)\n","        print(\"- Code Mean Shape:\", code_mean.shape)\n","        print(\"- Code Std Dev Shape:\", code_std_dev.shape)\n","\n","    print(\"\\nEncoder Model Testing Completed.\")\n","\n","# Example usage\n","config = {\n","    'num_hidden_units': 128,\n","    'n_channel': 10,\n","    'code_size': 64,\n","    'l_win': 48\n","}\n","\n","test_encoder(config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HetYlMmHQ26_","executionInfo":{"status":"ok","timestamp":1710630799819,"user_tz":300,"elapsed":94,"user":{"displayName":"Arman Nikkhah","userId":"16750917565129391933"}},"outputId":"5227cad7-fbb6-4826-eb41-e8eb52d79899"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Encoder Model Summary:\n","- The Encoder model takes an input tensor and encodes it into a latent code representation.\n","- It consists of convolutional layers followed by fully connected layers.\n","- The model outputs the latent code sample, mean, and standard deviation.\n","\n","Encoder Model Architecture:\n","Encoder(\n","  (conv1): Conv2d(1, 8, kernel_size=(3, 10), stride=(2, 1))\n","  (conv2): Conv2d(8, 16, kernel_size=(3, 10), stride=(2, 1))\n","  (conv3): Conv2d(16, 32, kernel_size=(3, 10), stride=(2, 1))\n","  (conv4): Conv2d(32, 128, kernel_size=(4, 10), stride=(1, 1), padding=valid)\n","  (conv5): Conv2d(32, 128, kernel_size=(6, 10), stride=(1, 1), padding=valid)\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (fc1): Linear(in_features=128, out_features=256, bias=True)\n","  (code_mean): Linear(in_features=256, out_features=64, bias=True)\n","  (code_std_dev): Linear(in_features=256, out_features=64, bias=True)\n",")\n","\n","Testing Encoder Model:\n","\n","Testing with input shape: (48, 10)\n","unsqueeze: torch.Size([1, 1, 48, 10])\n","conv_1: torch.Size([1, 8, 24, 10])\n","conv_2: torch.Size([1, 16, 12, 10])\n","conv_3: torch.Size([1, 32, 6, 10])\n","conv_5: torch.Size([1, 128, 1, 1])\n","flatten: torch.Size([1, 128])\n","finish encoder: \n","tensor([[-0.0685, -0.0109, -0.0720,  0.0596,  0.0583, -0.0031,  0.0243, -0.0263,\n","         -0.0612,  0.0652,  0.0216, -0.0820, -0.0728, -0.0913,  0.0912, -0.0242,\n","          0.0376, -0.0643, -0.0224, -0.0238, -0.0537, -0.0279,  0.0059,  0.0070,\n","         -0.0310, -0.0111, -0.0473, -0.0035, -0.0186,  0.0999, -0.0511, -0.0107,\n","         -0.0838, -0.0460,  0.0413, -0.0744,  0.0776,  0.0333, -0.0073,  0.0255,\n","          0.0352,  0.0083, -0.0523,  0.0055,  0.0048, -0.0275, -0.0129,  0.0852,\n","          0.0159,  0.0761,  0.0083,  0.0088,  0.0192,  0.0014,  0.0717, -0.0627,\n","         -0.0401, -0.0415, -0.0876, -0.0307,  0.0896,  0.0785, -0.0055, -0.0164]],\n","       grad_fn=<AddBackward0>)\n","\n","\n","Encoder Output:\n","- Code Sample Shape: torch.Size([1, 64])\n","- Code Mean Shape: torch.Size([1, 64])\n","- Code Std Dev Shape: torch.Size([1, 64])\n","\n","Encoder Model Testing Completed.\n"]}]},{"cell_type":"code","source":["class Decoder(nn.Module):\n","\n","    def __init__(self, config):\n","        super(Decoder, self).__init__()\n","        self.config = config\n","        self.is_code_input = config['is_code_input']  # Assuming this is determined elsewhere in your code\n","        self.num_hidden_units = config['num_hidden_units']\n","        self.n_channel = config['n_channel']\n","        self.l_win = config['l_win']\n","        self.code_size = config['code_size']\n","        self.TRAIN_sigma = config['TRAIN_sigma']\n","        self.sigma = config['sigma']\n","        self.sigma2_offset = config['sigma2_offset']\n","\n","        # Layers\n","        self.fc1 = nn.Linear(self.code_size, self.num_hidden_units)\n","        self.conv1 = nn.Conv2d(self.num_hidden_units, self.num_hidden_units, kernel_size=1, padding='same')\n","        self.conv2 = nn.Conv2d(self.num_hidden_units // 4, self.num_hidden_units // 4, kernel_size=(3, 1), stride=1, padding='same')\n","        self.conv3 = nn.Conv2d(self.num_hidden_units // 8, self.num_hidden_units // 8, kernel_size=(3, 1), stride=1, padding='same')\n","        self.conv4 = nn.Conv2d(self.num_hidden_units // 16, self.num_hidden_units // 16, kernel_size=(3, 1), stride=1, padding='same')\n","        self.conv5 = nn.Conv2d(self.num_hidden_units // 32, self.n_channel, kernel_size=(9, 1), stride=1, padding='valid') ## 16 -> 32 , valid -> same\n","\n","        self.conv_1 = nn.Conv2d(self.num_hidden_units, 256 * 3, kernel_size=1, padding='same')\n","        self.conv_2 = nn.Conv2d(256, 256, kernel_size=(3, 1), stride=1, padding='same')\n","        self.conv_3 = nn.Conv2d(128, 128, kernel_size=(3, 1), stride=1, padding='same')\n","        self.conv_4 = nn.Conv2d(32, 32, kernel_size=(3, 1), stride=1, padding='same')\n","        self.conv_5 = nn.Conv2d(16, self.n_channel, kernel_size=(5, self.n_channel), stride=1, padding='same')\n","\n","        # Assuming sigma2 and sigma2_offset are defined in config\n","\n","    def forward(self, code_input=None, code_sample=None):\n","\n","        encoded = code_input if self.is_code_input else code_sample\n","\n","        decoded_1 = F.leaky_relu(self.fc1(encoded))\n","        decoded_1 = decoded_1.view(-1, self.num_hidden_units, 1, 1)\n","        print(\"decoded_1 is: {}\".format(decoded_1.size()))\n","\n","        if self.l_win == 24:\n","            decoded_2 = F.leaky_relu(self.conv1(decoded_1))\n","            decoded_2 = decoded_2.view(-1, self.num_hidden_units // 4, 4, 1)\n","            print(\"decoded_2 is: {}\".format(decoded_2.size()))\n","\n","            decoded_3 = F.leaky_relu(self.conv2(decoded_2))\n","            decoded_3 = F.pixel_shuffle(decoded_3, upscale_factor=2)\n","            decoded_3 = decoded_3.view(-1, self.num_hidden_units // 8, 8, 1)\n","            print(\"decoded_3 is: {}\".format(decoded_3.size()))\n","\n","            decoded_4 = F.leaky_relu(self.conv3(decoded_3))\n","            decoded_4 = F.pixel_shuffle(decoded_4, upscale_factor=2)\n","            decoded_4 = decoded_4.view(-1, self.num_hidden_units // 16, 16, 1)\n","            print(\"decoded_4 is: {}\".format(decoded_4.size()))\n","\n","            decoded_5 = F.leaky_relu(self.conv4(decoded_4))\n","            decoded_5 = F.pixel_shuffle(decoded_5, upscale_factor=2)\n","            decoded_5 = decoded_5.view(-1, 16, self.num_hidden_units // 16, 1) ## test\n","            print(\"decoded_5 is: {}\".format(decoded_5.size()))\n","\n","            decoded = self.conv5(decoded_5)\n","            print(\"decoded_6 is: {}\".format(decoded.size()))\n","\n","            self.decoded = decoded.view(-1, self.l_win, self.n_channel)\n","\n","        if self.l_win == 48:\n","            decoded_2 = F.leaky_relu(self.conv_1(decoded_1))\n","            decoded_2 = decoded_2.view(-1, 256, 3, 1)\n","            print(\"decoded_2 is: {}\".format(decoded_2.size()))\n","\n","            decoded_3 = F.leaky_relu(self.conv_2(decoded_2))\n","            decoded_3 = F.pixel_shuffle(decoded_3, upscale_factor=2)\n","            decoded_3 = decoded_3.view(-1, 128, 6, 1)\n","            print(\"decoded_3 is: {}\".format(decoded_3.size()))\n","\n","            decoded_4 = F.leaky_relu(self.conv_3(decoded_3))\n","            decoded_4 = F.pixel_shuffle(decoded_4, upscale_factor=2)\n","            decoded_4 = decoded_4.view(-1, 32, 24, 1)\n","            print(\"decoded_4 is: {}\".format(decoded_4.size()))\n","\n","            decoded_5 = F.leaky_relu(self.conv_4(decoded_4))\n","            decoded_5 = F.pixel_shuffle(decoded_5, upscale_factor=2)\n","            decoded_5 = decoded_5.view(-1, 16, 48, 1)\n","            print(\"decoded_5 is: {}\".format(decoded_5.size()))\n","\n","            decoded = self.conv_5(decoded_5)\n","            print(\"decoded_6 is: {}\".format(decoded.size()))\n","\n","            self.decoded = decoded.view(-1, self.l_win, self.n_channel)\n","\n","        print(\"finish decoder: \\n{}\".format(self.decoded.size()))\n","        print('\\n')\n","\n","        return self.decoded"],"metadata":{"id":"4i4jOcbYNgxv","executionInfo":{"status":"ok","timestamp":1712779924647,"user_tz":300,"elapsed":336,"user":{"displayName":"Arman Nikkhah","userId":"16750917565129391933"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def test_decoder():\n","    # Sample configuration matching the expected structure\n","    config = {\n","        'is_code_input': True,\n","        'num_hidden_units': 512,\n","        'n_channel': 3,\n","        'l_win': 48,  # or 48 to test the other branch\n","        'code_size': 100,\n","        'TRAIN_sigma': 1,\n","        'sigma': 0.5,\n","        'sigma2_offset': 0.1  # Assuming sigma2_offset is defined somewhere\n","    }\n","\n","    # Initialize the Decoder with the given config\n","    decoder = Decoder(config)\n","\n","    print(decoder)\n","\n","\n","    # Create a sample input tensor\n","    if config['is_code_input']:\n","        code_input = torch.randn(1, config['code_size'])  # Batch size of 1\n","        output = decoder(code_input=code_input)\n","    else:\n","        code_sample = torch.randn(1, 24, config['code_size'])  # Batch size of 1\n","        output, sigma2 = decoder(code_sample=code_sample)\n","\n","    # Check the output shape\n","    expected_output_shape = (1, config['l_win'], config['n_channel'])\n","    assert output.shape == expected_output_shape, f\"Expected output shape {expected_output_shape}, got {output.shape}\"\n","\n","    print(\"Test passed successfully!\")\n","\n","# Run the test\n","test_decoder()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nlyOjCpK_4vh","executionInfo":{"status":"ok","timestamp":1712779933526,"user_tz":300,"elapsed":301,"user":{"displayName":"Arman Nikkhah","userId":"16750917565129391933"}},"outputId":"e99b959b-2e31-49cf-dba6-1f713e04fe2e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Decoder(\n","  (fc1): Linear(in_features=100, out_features=512, bias=True)\n","  (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), padding=same)\n","  (conv2): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=same)\n","  (conv3): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=same)\n","  (conv4): Conv2d(32, 32, kernel_size=(3, 1), stride=(1, 1), padding=same)\n","  (conv5): Conv2d(16, 3, kernel_size=(9, 1), stride=(1, 1), padding=valid)\n","  (conv_1): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1), padding=same)\n","  (conv_2): Conv2d(256, 256, kernel_size=(3, 1), stride=(1, 1), padding=same)\n","  (conv_3): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=same)\n","  (conv_4): Conv2d(32, 32, kernel_size=(3, 1), stride=(1, 1), padding=same)\n","  (conv_5): Conv2d(16, 3, kernel_size=(5, 3), stride=(1, 1), padding=same)\n",")\n","decoded_1 is: torch.Size([1, 512, 1, 1])\n","decoded_2 is: torch.Size([1, 256, 3, 1])\n","decoded_3 is: torch.Size([1, 128, 6, 1])\n","decoded_4 is: torch.Size([1, 32, 24, 1])\n","decoded_5 is: torch.Size([1, 16, 48, 1])\n","decoded_6 is: torch.Size([1, 3, 48, 1])\n","finish decoder: \n","torch.Size([1, 48, 3])\n","\n","\n","Test passed successfully!\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","\n","class lstmPyTorchModel(nn.Module):\n","    def __init__(self, config):\n","        super(lstmPyTorchModel, self).__init__()\n","\n","        self.config = config\n","        self.l_seq = config['l_seq']\n","        self.l_win = config['l_win']\n","        self.num_hidden_units_lstm = config['num_hidden_units_lstm']\n","        self.code_size = config['code_size']\n","\n","        self.lstm1 = nn.LSTM(self.code_size, self.num_hidden_units_lstm, batch_first=True)\n","        self.lstm2 = nn.LSTM(self.num_hidden_units_lstm, self.num_hidden_units_lstm, batch_first=True)\n","        self.lstm3 = nn.LSTM(self.num_hidden_units_lstm, self.code_size, batch_first=True)\n","\n","    def forward(self, x):\n","        x, _ = self.lstm1(x)\n","        x, _ = self.lstm2(x)\n","        x, _ = self.lstm3(x)\n","        return x\n","\n","    def produce_embeddings(self, model_vae, data, device):\n","        self.embedding_lstm_train = torch.zeros((data.n_train_lstm, self.l_seq, self.code_size), device=device)\n","        for i in range(data.n_train_lstm):\n","            with torch.no_grad():\n","                input_signal = data.train_set_lstm['data'][i].unsqueeze(0).to(device)\n","                code_input = torch.zeros((1, self.code_size), device=device)\n","                self.embedding_lstm_train[i] = model_vae(input_signal, False, code_input)[1]\n","\n","        print(\"Finish processing the embeddings of the entire dataset.\")\n","        print(\"The first a few embeddings are\\n{}\".format(self.embedding_lstm_train[0, 0:5]))\n","\n","        self.x_train = self.embedding_lstm_train[:, : self.l_seq - 1]\n","        self.y_train = self.embedding_lstm_train[:, 1:]\n","\n","        self.embedding_lstm_test = torch.zeros((data.n_val_lstm, self.l_seq, self.code_size), device=device)\n","        for i in range(data.n_val_lstm):\n","            with torch.no_grad():\n","                input_signal = data.val_set_lstm['data'][i].unsqueeze(0).to(device)\n","                code_input = torch.zeros((1, self.code_size), device=device)\n","                self.embedding_lstm_test[i] = model_vae(input_signal, False, code_input)[1]\n","\n","        self.x_test = self.embedding_lstm_test[:, :self.l_seq - 1]\n","        self.y_test = self.embedding_lstm_test[:, 1:]\n","\n","    def train(self, cp_callback):\n","        optimizer = optim.Adam(self.parameters(), lr=self.config['learning_rate_lstm'])\n","        criterion = nn.MSELoss()\n","\n","        for epoch in range(self.config['num_epochs_lstm']):\n","            self.train()\n","            running_loss = 0.0\n","            for i in range(0, self.x_train.size(0), self.config['batch_size_lstm']):\n","                batch_x = self.x_train[i:i+self.config['batch_size_lstm']]\n","                batch_y = self.y_train[i:i+self.config['batch_size_lstm']]\n","\n","                optimizer.zero_grad()\n","                outputs = self(batch_x)\n","                loss = criterion(outputs, batch_y)\n","                loss.backward()\n","                optimizer.step()\n","\n","                running_loss += loss.item()\n","\n","            epoch_loss = running_loss / (self.x_train.size(0) // config['batch_size_lstm'])\n","            print(f'Epoch {epoch+1}/{config[\"num_epochs_lstm\"]}, Loss: {epoch_loss:.4f}')\n","\n","            if cp_callback is not None:\n","                cp_callback(self, epoch_loss)\n","\n","            self.eval()\n","            with torch.no_grad():\n","                test_outputs = self(self.x_test)\n","                test_loss = criterion(test_outputs, self.y_test)\n","                print(f'Test Loss: {test_loss:.4f}')\n","\n","        print('Training finished.')\n","\n","\n","    def plot_reconstructed_lt_seq(self, idx_test, model_vae, data, device):\n","        with torch.no_grad():\n","            # VAE reconstruction\n","            input_signal = torch.zeros((self.l_seq, self.l_win, self.config['n_channel']), device=device)\n","            code_input = self.embedding_lstm_test[idx_test].unsqueeze(0).to(device)\n","            decoded_seq_vae = model_vae(input_signal, True, code_input)[0].squeeze().cpu().numpy()\n","            print(f\"Decoded seq from VAE: {decoded_seq_vae.shape}\")\n","\n","            # LSTM reconstruction\n","            input_signal = torch.zeros((self.l_seq - 1, self.l_win, self.config['n_channel']), device=device)\n","            lstm_embedding_test = self.x_test[idx_test].unsqueeze(0).to(device)\n","            decoded_seq_lstm = model_vae(input_signal, True, lstm_embedding_test)[0].squeeze().cpu().numpy()\n","            print(f\"Decoded seq from lstm: {decoded_seq_lstm.shape}\")\n","\n","        fig, axs = plt.subplots(self.config['n_channel'], 2, figsize=(15, 4.5 * self.config['n_channel']), edgecolor='k')\n","        fig.subplots_adjust(hspace=.4, wspace=.4)\n","        axs = axs.ravel()\n","        for j in range(self.config['n_channel']):\n","            for i in range(2):\n","                axs[i + j * 2].plot(np.arange(0, self.l_seq * self.l_win),\n","                                    np.reshape(data.val_set_lstm['data'][idx_test, :, :, j],\n","                                               (self.l_seq * self.l_win)))\n","                axs[i + j * 2].grid(True)\n","                axs[i + j * 2].set_xlim(0, self.l_seq * self.l_win)\n","                axs[i + j * 2].set_xlabel('samples')\n","            if self.config['n_channel'] == 1:\n","                axs[0 + j * 2].plot(np.arange(0, self.l_seq * self.l_win),\n","                                    np.reshape(decoded_seq_vae, (self.l_seq * self.l_win)), 'r--')\n","                axs[1 + j * 2].plot(np.arange(self.l_win, self.l_seq * self.l_win),\n","                                    np.reshape(decoded_seq_lstm, ((self.l_seq - 1) * self.l_win)), 'g--')\n","            else:\n","                axs[0 + j * 2].plot(np.arange(0, self.l_seq * self.l_win),\n","                                    np.reshape(decoded_seq_vae[:, :, j], (self.l_seq * self.l_win)), 'r--')\n","                axs[1 + j * 2].plot(np.arange(self.l_win, self.l_seq * self.l_win),\n","                                    np.reshape(decoded_seq_lstm[:, :, j], ((self.l_seq - 1) * self.l_win)), 'g--')\n","            axs[0 + j * 2].set_title(f'VAE reconstruction - channel {j}')\n","            axs[1 + j * 2].set_title(f'LSTM reconstruction - channel {j}')\n","            for i in range(2):\n","                axs[i + j * 2].legend(('ground truth', 'reconstruction'))\n","        plt.savefig(f\"{self.config['result_dir']}lstm_long_seq_recons_{idx_test}.pdf\")\n","        plt.close()\n","\n","\n","    def plot_lstm_embedding_prediction(self, idx_test, config, model_vae, data, device):\n","        self.plot_reconstructed_lt_seq(idx_test, config, model_vae, data, device)\n","\n","        fig, axs = plt.subplots(2, self.code_size // 2, figsize=(15, 5.5), edgecolor='k')\n","        fig.subplots_adjust(hspace=.4, wspace=.4)\n","        axs = axs.ravel()\n","        for i in range(self.code_size):\n","            axs[i].plot(torch.arange(1, self.l_seq), self.embedding_lstm_test[idx_test, 1:, i].squeeze().cpu().numpy())\n","            axs[i].plot(torch.arange(1, self.l_seq), self.x_test[idx_test, :, i].squeeze().cpu().numpy())\n","            axs[i].set_xlim(1, self.l_seq - 1)\n","            axs[i].set_ylim(-2.5, 2.5)\n","            axs[i].grid(True)\n","            axs[i].set_title(f'Embedding dim {i}')\n","            axs[i].set_xlabel('windows')\n","            if i == self.code_size - 1:\n","                axs[i].legend(('VAE\\nembedding', 'LSTM\\nembedding'))\n","        plt.savefig(f\"{config['result_dir']}lstm_seq_embedding_{idx_test}.pdf\")\n","        plt.close()"],"metadata":{"id":"gSyWZEphinTi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import unittest\n","import torch\n","\n","class TestLstmPyTorchModel(unittest.TestCase):\n","    def setUp(self):\n","        # Set up the test environment and initialize required objects\n","        self.config = {\n","            'l_seq': 10,\n","            'l_win': 5,\n","            'num_hidden_units_lstm': 64,\n","            'code_size': 32,\n","            'learning_rate_lstm': 0.001,\n","            'num_epochs_lstm': 10,\n","            'batch_size_lstm': 32,\n","            'n_channel': 1,\n","            'result_dir': './results/'\n","        }\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        self.model = lstmPyTorchModel(self.config).to(self.device)\n","        self.model_vae = vaeModel(self.config).to(self.device)\n","        self.data = Data(self.config)\n","\n","    def test_produce_embeddings(self):\n","        # Test the produce_embeddings method\n","        self.model.produce_embeddings(self.model_vae, self.data, self.device)\n","\n","        # Assert the shape of the generated embeddings\n","        self.assertEqual(self.model.embedding_lstm_train.shape, (self.data.n_train_lstm, self.config['l_seq'], self.config['code_size']))\n","        self.assertEqual(self.model.embedding_lstm_test.shape, (self.data.n_val_lstm, self.config['l_seq'], self.config['code_size']))\n","\n","        # Assert the shape of the input and target sequences\n","        self.assertEqual(self.model.x_train.shape, (self.data.n_train_lstm, self.config['l_seq'] - 1, self.config['code_size']))\n","        self.assertEqual(self.model.y_train.shape, (self.data.n_train_lstm, self.config['l_seq'] - 1, self.config['code_size']))\n","        self.assertEqual(self.model.x_test.shape, (self.data.n_val_lstm, self.config['l_seq'] - 1, self.config['code_size']))\n","        self.assertEqual(self.model.y_test.shape, (self.data.n_val_lstm, self.config['l_seq'] - 1, self.config['code_size']))\n","\n","    def test_forward(self):\n","        # Test the forward method\n","        batch_size = 16\n","        input_seq = torch.randn(batch_size, self.config['l_seq'] - 1, self.config['code_size']).to(self.device)\n","        output_seq = self.model(input_seq)\n","\n","        # Assert the shape of the output sequence\n","        self.assertEqual(output_seq.shape, (batch_size, self.config['l_seq'] - 1, self.config['code_size']))\n","\n","    def test_train(self):\n","        # Test the train method\n","        def checkpoint_callback(model, loss):\n","            # Callback function for checkpointing during training\n","            pass\n","\n","        self.model.train(checkpoint_callback)\n","\n","        # Assert that the model is in evaluation mode after training\n","        self.assertFalse(self.model.training)\n","\n","    def test_plot_reconstructed_lt_seq(self):\n","        # Test the plot_reconstructed_lt_seq method\n","        idx_test = 0\n","        self.model.plot_reconstructed_lt_seq(idx_test, self.model_vae, self.data, self.device)\n","\n","        # Assert that the plot file is generated\n","        plot_file = f\"{self.config['result_dir']}lstm_long_seq_recons_{idx_test}.pdf\"\n","        self.assertTrue(os.path.exists(plot_file))\n","\n","    def test_plot_lstm_embedding_prediction(self):\n","        # Test the plot_lstm_embedding_prediction method\n","        idx_test = 0\n","        self.model.plot_lstm_embedding_prediction(idx_test, self.config, self.model_vae, self.data, self.device)\n","\n","        # Assert that the plot file is generated\n","        plot_file = f\"{self.config['result_dir']}lstm_seq_embedding_{idx_test}.pdf\"\n","        self.assertTrue(os.path.exists(plot_file))\n","\n","if __name__ == '__main__':\n","    unittest.main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"kuzE5EGQAe21","executionInfo":{"status":"error","timestamp":1710638675464,"user_tz":300,"elapsed":155,"user":{"displayName":"Arman Nikkhah","userId":"16750917565129391933"}},"outputId":"d440567c-a1f9-46f3-e4d3-cda9e67c9c69"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["E\n","======================================================================\n","ERROR: /root/ (unittest.loader._FailedTest)\n","----------------------------------------------------------------------\n","AttributeError: module '__main__' has no attribute '/root/'\n","\n","----------------------------------------------------------------------\n","Ran 1 test in 0.013s\n","\n","FAILED (errors=1)\n"]},{"output_type":"error","ename":"SystemExit","evalue":"True","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m True\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","\n","class BaseModel(nn.Module):\n","    def __init__(self, config):\n","        super(BaseModel, self).__init__()\n","        self.config = config\n","        self.two_pi = torch.tensor(2 * np.pi)\n","        self.global_step = 0\n","        self.cur_epoch = 0\n","\n","    def save(self, checkpoint_path):\n","        print(\"Saving model...\")\n","        torch.save(self.state_dict(), checkpoint_path)\n","        print(\"Model saved.\")\n","\n","    def load(self, checkpoint_path):\n","        print(\"checkpoint_dir at loading: {}\".format(checkpoint_path))\n","        if os.path.exists(checkpoint_path):\n","            print(\"Loading model checkpoint {} ...\\n\".format(checkpoint_path))\n","            self.load_state_dict(torch.load(checkpoint_path))\n","            print(\"Model loaded.\")\n","        else:\n","            print(\"No model loaded.\")\n","\n","    def define_loss(self):\n","        # KL divergence loss - analytical result\n","        KL_loss = 0.5 * (torch.sum(self.code_mean ** 2, dim=1)\n","                         + torch.sum(self.code_std_dev ** 2, dim=1)\n","                         - torch.sum(torch.log(self.code_std_dev ** 2), dim=1)\n","                         - self.config['code_size'])\n","        self.KL_loss = torch.mean(KL_loss)\n","\n","        # norm 1 of standard deviation of the sample-wise encoder prediction\n","        self.std_dev_norm = torch.mean(self.code_std_dev, dim=0)\n","\n","        weighted_reconstruction_error_dataset = torch.sum(\n","            (self.original_signal - self.decoded) ** 2, dim=[1, 2])\n","        weighted_reconstruction_error_dataset = torch.mean(weighted_reconstruction_error_dataset)\n","        self.weighted_reconstruction_error_dataset = weighted_reconstruction_error_dataset / (2 * self.sigma2)\n","\n","        # least squared reconstruction error\n","        ls_reconstruction_error = torch.sum(\n","            (self.original_signal - self.decoded) ** 2, dim=[1, 2])\n","        self.ls_reconstruction_error = torch.mean(ls_reconstruction_error)\n","\n","        # sigma regularisor - input elbo\n","        self.sigma_regularisor_dataset = self.input_dims / 2 * torch.log(self.sigma2)\n","        two_pi = self.input_dims / 2 * self.two_pi\n","\n","        self.elbo_loss = two_pi + self.sigma_regularisor_dataset + \\\n","                         0.5 * self.weighted_reconstruction_error_dataset + self.KL_loss\n","\n","    def training_variables(self):\n","        encoder_vars = list(self.encoder.parameters())\n","        decoder_vars = list(self.decoder.parameters())\n","        sigma_vars = [self.sigma2]\n","        self.train_vars_VAE = encoder_vars + decoder_vars + sigma_vars\n","\n","        num_encoder = sum(p.numel() for p in self.encoder.parameters() if p.requires_grad)\n","        num_decoder = sum(p.numel() for p in self.decoder.parameters() if p.requires_grad)\n","        num_sigma2 = self.sigma2.numel()\n","        self.num_vars_total = num_decoder + num_encoder + num_sigma2\n","        print(\"Total number of trainable parameters in the VAE network is: {}\".format(self.num_vars_total))\n","\n","    def compute_gradients(self):\n","        self.optimizer = torch.optim.Adam(self.train_vars_VAE, lr=self.lr, betas=(0.9, 0.95))\n","        self.train_step_gradient = self.optimizer.step()\n","        print(\"Reach the definition of loss for VAE\")\n","\n","    def clip_grad(self, grad):\n","        if grad is None:\n","            return grad\n","        return torch.clamp(grad, -1, 1)\n","\n","\n","\n","class BaseTrain:\n","    def __init__(self, model, data, config):\n","        \"\"\"\n","        Initializes the training session with the necessary components.\n","\n","        :param model: The model to be trained.\n","        :param data: The dataset for training and validation.\n","        :param config: Configuration dictionary with training parameters and paths.\n","\n","        Initializes PyTorch variables, prepares for training, and initializes\n","        various lists to keep track of training and validation losses, as well as\n","        other metrics like reconstruction and KL divergence losses.\n","        \"\"\"\n","        self.model = model\n","        self.config = config\n","        self.data = data\n","\n","        # Initialize lists to keep track of various training and validation metrics\n","        self.train_loss = []\n","        self.val_loss = []\n","        self.train_loss_ave_epoch = []\n","        self.val_loss_ave_epoch = []\n","        self.recons_loss_train = []\n","        self.recons_loss_val = []\n","        self.KL_loss_train = []\n","        self.KL_loss_val = []\n","        self.sample_std_dev_train = []\n","        self.sample_std_dev_val = []\n","        self.iter_epochs_list = []\n","        self.test_sigma2 = []\n","\n","    def train(self):\n","        \"\"\"\n","        Starts the training process over a specified number of epochs.\n","\n","        Tracks and prints the elapsed time and estimated remaining time for training.\n","        Utilizes the `train_epoch` method (not defined in this snippet) for actual\n","        training logic specific to each epoch.\n","        \"\"\"\n","        self.start_time = time.time()\n","        for cur_epoch in range(self.config['num_epochs_vae']):\n","            self.train_epoch()  # Train for one epoch, method to be defined elsewhere\n","\n","            # Calculate and print time elapsed and estimated remaining training time\n","            self.current_time = time.time()\n","            elapsed_time = (self.current_time - self.start_time) / 60\n","            est_remaining_time = (self.current_time - self.start_time) / (cur_epoch + 1) * (self.config['num_epochs_vae'] - cur_epoch - 1) / 60\n","            print(\"Already trained for {} min; Remaining {} min.\".format(elapsed_time, est_remaining_time))\n","\n","            # Increment the current epoch counter in the model\n","            self.model.cur_epoch += 1\n","\n","    def save_variables_VAE(self):\n","        \"\"\"\n","        Saves important variables and metrics for inspection after training.\n","\n","        Saves metrics such as training and validation losses, reconstruction and KL\n","        divergence losses, and model parameters to a file.\n","        \"\"\"\n","        # Construct the filename from configuration parameters\n","        file_name = \"{}{}-batch-{}-epoch-{}-code-{}-lr-{}.npz\".format(self.config['result_dir'],\n","                                                                      self.config['exp_name'],\n","                                                                      self.config['batch_size'],\n","                                                                      self.config['num_epochs_vae'],\n","                                                                      self.config['code_size'],\n","                                                                      self.config['learning_rate_vae'])\n","        # Save metrics to the specified file\n","        np.savez(file_name,\n","                 iter_list_val=self.iter_epochs_list,\n","                 train_loss=self.train_loss,\n","                 val_loss=self.val_loss,\n","                 n_train_iter=self.n_train_iter,\n","                 n_val_iter=self.n_val_iter,\n","                 recons_loss_train=self.recons_loss_train,\n","                 recons_loss_val=self.recons_loss_val,\n","                 KL_loss_train=self.KL_loss_train,\n","                 KL_loss_val=self.KL_loss_val,\n","                 num_para_all=sum(p.numel() for p in self.model.parameters()),\n","                 sigma2=self.test_sigma2)\n","\n","    def plot_train_and_val_loss(self):\n","        \"\"\"\n","        Plots training and validation loss over time, as well as a breakdown of the\n","        validation loss into its components and the evolution of sigma^2.\n","\n","        Generates three plots: overall training and validation losses, validation\n","        loss components (reconstruction and KL divergence losses), and sigma^2 values\n","        over the course of training.\n","        \"\"\"\n","        # Plot overall training and validation losses\n","        plt.clf()\n","        figure(num=1, figsize=(8, 6))\n","        plot(self.train_loss, 'b-')\n","        plot(self.iter_epochs_list, self.val_loss_ave_epoch, 'r-')\n","        plt.legend(('Training Loss (Total)', 'Validation Loss'))\n","        plt.title('Training Loss Over Iterations (Validation @ Epochs)')\n","        plt.ylabel('Total Loss')\n","        plt.xlabel('Iterations')\n","        plt.grid(True)\n","        savefig(self.config['result_dir'] + '/loss.png')\n","\n","        # Plot breakdown of validation loss into reconstruction and KL divergence losses\n","        plt.clf()\n","        figure(num=1, figsize=(8, 6))\n","        plot(self.recons_loss_val, 'b-')\n","        plot(self.KL_loss_val, 'r-')\n","        plt.legend(('Reconstruction Loss', 'KL Divergence Loss'))\n","        plt.title('Validation Loss Breakdown')\n","        plt.ylabel('Loss')\n","        plt.xlabel('Number of Batches')\n","        plt.grid(True)\n","        savefig(self.config['result_dir'] + '/val-loss.png')\n","\n","        # Plot the evolution of sigma^2 over training\n","        plt.clf()\n","        figure(num=1, figsize=(8, 6))\n","        plot(self.test_sigma2, 'b-')\n","        plt.title('Sigma^2 Over Training')\n","        plt.ylabel('Sigma^2')\n","        plt.xlabel('Iteration')\n","        plt.grid(True)\n","        savefig(self.config['result_dir'] + '/sigma2.png')"],"metadata":{"id":"UR1RPK4fPd_9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class VAEmodel(BaseModel):\n","    def __init__(self, config):\n","        super(VAEmodel, self).__init__()\n","        self.encoder = Encoder(config)\n","        self.decoder = Decoder(config)\n","        self.config = config\n","\n","        # Define sigma parameter\n","        self.sigma_trainable = self.config['TRAIN_sigma'] == 1\n","        sigma_value = self.config['sigma']\n","        self.sigma = nn.Parameter(torch.tensor(sigma_value, dtype=torch.float32), requires_grad=self.sigma_trainable)\n","        self.sigma2_offset = torch.tensor(config.get('sigma2_offset', 0), dtype=torch.float32)\n","\n","    def reparameterize(self, mean, log_var):\n","        std = torch.exp(0.5 * log_var)\n","        eps = torch.randn_like(std)\n","        return mean + eps * std\n","\n","    def forward(self, x):\n","        mean, log_var = self.encoder(x)\n","        z = self.reparameterize(mean, log_var)\n","        z = z.unsqueeze(-1).unsqueeze(-1)  # Reshape for the decoder\n","        return self.decoder(z), mean, log_var\n","\n","    @property\n","    def sigma2(self):\n","        sigma_squared = self.sigma ** 2\n","        if self.sigma_trainable:\n","            sigma_squared += self.sigma2_offset\n","        return sigma_squared\n"],"metadata":{"id":"PBS04gOh07yI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Example configuration\n","config = {\n","    'l_win': 24,\n","    'n_channel': 1,\n","    'num_hidden_units': 64,\n","    'code_size': 10,\n","    'TRAIN_sigma': 1,\n","    'sigma': 0.1,\n","    'sigma2_offset': 0.01\n","}\n","\n","model = VAEmodel(config)\n","print(model)"],"metadata":{"id":"rpBD65H_2J0j"},"execution_count":null,"outputs":[]}]}